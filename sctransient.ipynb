{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402b95d-c690-4bf6-8cc1-6f76beb4f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   - 11282025_PaperRevision_Exp2_Lahi_report.pg_matrix (1).tsv  (protein x sample intensities)\n",
    "# Output:\n",
    "#   - exp2_rev_psupertime.h5ad (AnnData with psupertime results in .obs)\n",
    "#\n",
    "# Install (if needed):\n",
    "#   pip install anndata scanpy pandas numpy scipy scikit-learn\n",
    "#   pip install git+https://github.com/AlexandreHutton/pyPsupertime.git  # updated version of pyPsupertime\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import sklearn\n",
    "from pypsupertime import Psupertime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Union\n",
    "from pywt import Wavelet\n",
    "\n",
    "from scTransient.windowing import ConfinedGaussianWindow\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scTransient.utils import permutation_dist\n",
    "from scTransient.metrics import transient_event_score\n",
    "from scTransient.utils import convert_to_signal\n",
    "from scTransient.windowing import ConfinedGaussianWindow\n",
    "from scipy.stats import false_discovery_control\n",
    "from scTransient.wavelets import WaveletTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18c2a6-6894-44e1-a69d-dd8d0baf2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "data_path = \"11282025_PaperRevision_Exp2_Lahi_report.pg_matrix.tsv\"\n",
    "min_detect_frac = 0.30  # minimum detection fraction, used for filtering out samples\n",
    "\n",
    "h5ad_path = \"exp2_subset_for_psupertime.h5ad\"  # intermediate data path for psupertime\n",
    "\n",
    "ptime_col = \"psupertime\"  # column where pseudotime is stored\n",
    "n_windows = 30  # number of windows to use to convert samples to pseudotime signal\n",
    "sigma = 0.10  # std of gaussian window\n",
    "max_distance = 0.25  # max distance before cutting to 0 for confined gaussian window\n",
    "\n",
    "wavelet = \"mexh\"  # wavelet to use\n",
    "scales = np.array([2, 4, 8])  # scales to use for wavelet\n",
    "\n",
    "zscore_genes = True  # whether to convert abundances to z-scores\n",
    "detrend_monotonic = True  # whether to remove linear trends\n",
    "edge_frac = 0.02\n",
    "\n",
    "do_perms = True  # whether to do permutation testing to get p-values(takes a while)\n",
    "n_perms = 10  # number of permutations\n",
    "topK_for_perms = 5000  # top genes to select\n",
    "seed = 1  # random seed\n",
    "\n",
    "do_cluster = True  # whether to cluster gene signals (kmeans)\n",
    "n_clusters = 4  # number of clusters to use\n",
    "cluster_topN = 5000  # set None to cluster all genes in res\n",
    "\n",
    "top_plot_n = 12\n",
    "\n",
    "# Cache: change this string if you change parameters and want a fresh run\n",
    "cache_path = \"psupertime_transient_wavelet_cache.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4ce15-0766-4379-81a4-88589143169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load matrix and parse sample metadata from column names\n",
    "df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "\n",
    "# adjust if your sample columns use a different suffix than \".raw\"\n",
    "sample_cols = [c for c in df.columns if c.lower().endswith(\".raw\")]\n",
    "if len(sample_cols) == 0:\n",
    "    raise ValueError(\"No sample columns found ending in '.raw'. Update sample_cols selection.\")\n",
    "\n",
    "def basename_win(path):\n",
    "    return re.split(r\"[\\\\/]\", path)[-1]\n",
    "\n",
    "def parse_sample(col):\n",
    "    # Column looks like: D:\\...\\A1.raw or similar (maybe with _Pl2 before .raw)\n",
    "    b = os.path.splitext(basename_win(col))[0]     # e.g. \"A1\" or \"A1_Pl2\"\n",
    "    m = re.match(r\"([A-H]\\d{1,2})(?:_Pl2)?$\", b)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Could not parse well from sample column: {col}\")\n",
    "    well = m.group(1)\n",
    "    plate = 2 if b.endswith(\"_Pl2\") else 1\n",
    "    row = well[0]\n",
    "    colnum = int(well[1:])\n",
    "\n",
    "    # Plate 1: weeks 8,6,4,2 across triplets of columns, within each triplet: rev, hom, het\n",
    "    # Plate 2: week 1 across columns: rev, hom, het\n",
    "    if plate == 1:\n",
    "        trip = (colnum - 1) // 3\n",
    "        week = {0: 8, 1: 6, 2: 4, 3: 2}[trip]\n",
    "        genotype = {0: \"rev\", 1: \"hom\", 2: \"het\"}[(colnum - 1) % 3]\n",
    "    else:\n",
    "        week = 1\n",
    "        genotype = {1: \"rev\", 2: \"hom\", 3: \"het\"}[colnum]\n",
    "\n",
    "    return dict(sample=b, well=well, plate=plate, row=row, col=colnum, week=int(week), genotype=genotype)\n",
    "\n",
    "obs = pd.DataFrame([parse_sample(c) for c in sample_cols], index=sample_cols)\n",
    "\n",
    "\n",
    "# 2) Pick the subset you want trajectories for\n",
    "keep_mask = obs[\"genotype\"].eq(\"rev\")\n",
    "\n",
    "\n",
    "obs_sub = obs.loc[keep_mask].copy()\n",
    "sample_cols_sub = obs_sub.index.tolist()\n",
    "if len(sample_cols_sub) < 5:\n",
    "    raise ValueError(f\"Too few samples kept ({len(sample_cols_sub)}). Check keep_mask.\")\n",
    "\n",
    "\n",
    "# 3) Build expression matrix (samples x genes) for AnnData\n",
    "gene = (\n",
    "    df[\"Genes\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.split(\";\")\n",
    "    .str[0]\n",
    "    .str.strip()\n",
    ")\n",
    "mask_gene = gene.ne(\"\")  # remove blank genes\n",
    "df2 = df.loc[mask_gene].copy()\n",
    "df2[\"gene\"] = gene.loc[mask_gene].values\n",
    "\n",
    "# Pull intensities and do simple proteomics-friendly transforms\n",
    "X = df2[sample_cols_sub].replace(0, np.nan).astype(float)\n",
    "\n",
    "# Filter to reduce missingness (tune if you want)\n",
    "min_detect_frac = 0.30\n",
    "keep_feat = (X.notna().mean(axis=1) >= min_detect_frac)\n",
    "X = X.loc[keep_feat]\n",
    "df2 = df2.loc[keep_feat]\n",
    "\n",
    "# Log2 transform with a small offset (min positive)\n",
    "vals = X.values\n",
    "min_pos = np.nanmin(vals[vals > 0]) if np.any(vals > 0) else 1.0\n",
    "X_log = np.log2(X + min_pos)\n",
    "\n",
    "# Per-sample median centering\n",
    "X_norm = X_log.sub(X_log.median(axis=0), axis=1)\n",
    "\n",
    "# Collapse to gene-level (median across protein rows per gene)\n",
    "X_gene = X_norm.assign(gene=df2[\"gene\"]).groupby(\"gene\").median()   # genes x samples\n",
    "\n",
    "# Samples x genes for AnnData\n",
    "M = X_gene.T\n",
    "M = M.apply(lambda col: col.fillna(col.median()), axis=0)\n",
    "\n",
    "adata = ad.AnnData(\n",
    "    X=M.values,\n",
    "    obs=obs_sub.loc[M.index].copy(),\n",
    "    var=pd.DataFrame(index=M.columns)\n",
    ")\n",
    "\n",
    "# pypsupertime expects a numeric ordinal label in .obs\n",
    "# Use \"week\" as the ordinal time label\n",
    "adata.obs[\"time\"] = adata.obs[\"week\"].astype(int)\n",
    "\n",
    "\n",
    "# 4) Run pypsupertime\n",
    "# Easiest path is: write .h5ad, then p.run(path, \"time\")\n",
    "adata.write_h5ad(h5ad_path)\n",
    "\n",
    "p = Psupertime()\n",
    "adata_out = p.run(h5ad_path, \"time\")\n",
    "\n",
    "# 5) Inspect / export results\n",
    "print(\"obs columns:\", list(adata_out.obs.columns))\n",
    "print(\"var columns:\", list(adata_out.var.columns))\n",
    "\n",
    "# search for likely keys:\n",
    "likely = [c for c in adata_out.obs.columns if \"super\" in c.lower() or \"pseudo\" in c.lower() or \"time\" == c.lower()]\n",
    "print(\"likely pseudotime columns:\", likely)\n",
    "\n",
    "# Save output\n",
    "out_path = \"exp2_rev_psupertime.h5ad\"\n",
    "adata_out.write_h5ad(out_path)\n",
    "print(\"Wrote:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77771a58-1df6-4e19-bc1b-8937627014bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot_grid_search(title=\"Grid Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7e03d-740c-4324-877a-683c7e7dcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot_model_perf((adata_out.X, adata_out.obs.time), figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ff2e6-208b-42f8-9647-87361c8f5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "_ = p.plot_identified_gene_coefficients(adata_out, n_top=6, ax=ax[1,1])\n",
    "_ = p.plot_labels_over_psupertime(adata_out, \"time\", ax=ax[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d581c8-ba9a-46f6-a7d6-6ab755faf3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([c for c in adata_out.obs.columns if \"time\" in c.lower()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088271b-d107-4f46-b5a9-f186f7091eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genes to inspect\n",
    "genes = [\n",
    "    \"DCC\", \"TH\", \"CAMK2A\", \"DYRK1A\",\n",
    "    \"SRGAP1\", \"SEPTIN8\", \"HPCAL4\"\n",
    "]\n",
    "\n",
    "ptime_col = \"psupertime\"   # change if needed\n",
    "\n",
    "# ensure genes exist after psupertime filtering\n",
    "genes = [g for g in genes if g in adata_out.var_names]\n",
    "print(\"Plotting:\", genes)\n",
    "\n",
    "# sort cells by pseudotime\n",
    "order = np.argsort(adata_out.obs[ptime_col].values)\n",
    "ptime = adata_out.obs[ptime_col].values[order]\n",
    "\n",
    "n = len(genes)\n",
    "fig, axes = plt.subplots(n, 1, figsize=(6, 1.8*n), sharex=True)\n",
    "\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, g in zip(axes, genes):\n",
    "    y = adata_out.X[order, adata_out.var_names.get_loc(g)]\n",
    "    ax.plot(ptime, y, marker=\"o\", linestyle=\"-\", alpha=0.7)\n",
    "    ax.set_ylabel(g)\n",
    "    ax.axhline(0, color=\"gray\", lw=0.5, ls=\"--\")\n",
    "\n",
    "axes[-1].set_xlabel(\"psupertime\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcda8d-dd71-4b1d-9cd4-18b383394141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For visualizing the wavelet - in case you're unsure about what the wavelets look like with data.\n",
    "\n",
    "# def ricker(center, pos, scale):\n",
    "#     return (2/(np.sqrt(3*scale)*np.power(np.pi,1/4))) * (1 - ((pos-center)/scale)**2) * (np.exp((-(pos-center)**2)/(2*scale**2)))\n",
    "\n",
    "# x = np.linspace(-6,6,1024)\n",
    "# wlet = ricker(0, x, scale=2)\n",
    "# plt.plot(x, wlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2affae-64cc-4627-944f-76cc73eefca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here, \"num_samples\" corresponds to the number of windows you would use for converting samples to a signal. \n",
    "# # This affects what the scale means for the wavelet.\n",
    "# num_samples = 40  \n",
    "# # For visualizing the wavelet of different scales with different window counts.\n",
    "\n",
    "# for num_samples in [20,30,40]:\n",
    "#     plt.figure()\n",
    "#     x = np.linspace(0,num_samples-1,num_samples)\n",
    "#     c = np.mean(x)\n",
    "#     # scales = [2,4,8,16]\n",
    "#     for s in scales:\n",
    "#         plt.plot(x, ricker(c, x, s), \".-\", label=f\"{s}\")\n",
    "#     plt.legend(title=\"Scales\")\n",
    "#     plt.title(f\"Wavelets of different scales (n={num_samples})\")\n",
    "#     plt.ylabel(\"Wavelet value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b156c7-4ad2-48bc-8903-d2c6fe9240b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptime = adata_out.obs[\"psupertime\"]\n",
    "ptime = (ptime - np.min(ptime)) / (np.max(ptime) - np.min(ptime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8200ae-c8c3-406f-bca0-32bcc46f2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_dense(X):\n",
    "    try:\n",
    "        import scipy.sparse as sp\n",
    "        if sp.issparse(X):\n",
    "            return X.toarray()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(X)\n",
    "\n",
    "\n",
    "def _make_params_dict():\n",
    "    return {\n",
    "        \"ptime_col\": ptime_col,\n",
    "        \"n_windows\": n_windows,\n",
    "        \"sigma\": sigma,\n",
    "        \"max_distance\": max_distance,\n",
    "        \"wavelet\": wavelet,\n",
    "        \"scales\": scales.astype(int).tolist(),\n",
    "        \"zscore_genes\": bool(zscore_genes),\n",
    "        \"detrend_monotonic\": bool(detrend_monotonic),\n",
    "        \"edge_frac\": float(edge_frac),\n",
    "        \"do_perms\": bool(do_perms),\n",
    "        \"n_perms\": int(n_perms),\n",
    "        \"topK_for_perms\": int(topK_for_perms),\n",
    "        \"seed\": int(seed),\n",
    "        \"do_cluster\": bool(do_cluster),\n",
    "        \"n_clusters\": int(n_clusters),\n",
    "        \"cluster_topN\": None if cluster_topN is None else int(cluster_topN),\n",
    "        \"top_plot_n\": int(top_plot_n),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_or_load(cache_path: str = None):\n",
    "    params = _make_params_dict()\n",
    "\n",
    "    if cache_path is not None and os.path.exists(cache_path):\n",
    "        print(f\"[cache] Found {cache_path}, loading...\")\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            out = pickle.load(f)\n",
    "\n",
    "        old = out.get(\"params\", {})\n",
    "        if old != params:\n",
    "            print(\"[cache] Cache params differ from current settings.\")\n",
    "            print(\"        Delete/rename cache_path if you want a full recompute.\")\n",
    "            print(\"        Using cached results anyway.\")\n",
    "        print(\"[cache] Loaded keys:\", list(out.keys()))\n",
    "        return out\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 1) Pull ordered data\n",
    "    print(\"[1/8] Pulling psupertime and ordering cells...\")\n",
    "    if ptime_col not in adata_out.obs.columns:\n",
    "        raise KeyError(f\"{ptime_col} not in adata_out.obs. Available: {list(adata_out.obs.columns)}\")\n",
    "\n",
    "    ptime = adata_out.obs[ptime_col].to_numpy().astype(float)\n",
    "    order = np.argsort(ptime)\n",
    "    ptime = ptime[order]\n",
    "    ptime = (ptime - ptime.min()) / (ptime.max() - ptime.min() + 1e-12)  # normalize pseudotime range to 0-1\n",
    "\n",
    "    print(\"[2/8] Loading X and var names...\")\n",
    "    X = _to_dense(adata_out.X)[order, :].astype(float)\n",
    "\n",
    "    var_names_arr = np.asarray(list(adata_out.var_names), dtype=object)\n",
    "    var_names_arr = np.array([str(x) for x in var_names_arr], dtype=str)\n",
    "    gene_to_idx = {g: i for i, g in enumerate(var_names_arr)}\n",
    "\n",
    "    print(f\"       cells: {X.shape[0]:,}   genes: {X.shape[1]:,}\")\n",
    "\n",
    "    if zscore_genes:\n",
    "        print(\"[3/8] Z-scoring per gene (across cells)...\")\n",
    "        X = (X - X.mean(axis=0, keepdims=True)) / (X.std(axis=0, keepdims=True) + 1e-12)\n",
    "    else:\n",
    "        print(\"[3/8] Skipping z-scoring (zscore_genes=False)\")\n",
    "\n",
    "    # 2) Confined Gaussian windowing\n",
    "    print(\"[4/8] Building window weights and computing windowed signals (matmul)...\")\n",
    "    conf_gauss_window = ConfinedGaussianWindow(n_windows=params[\"n_windows\"],\n",
    "                                               sigma=params[\"sigma\"],\n",
    "                                               max_distance=params[\"max_distance\"],\n",
    "                                               signal_domain=(np.min(ptime), np.max(ptime)))\n",
    "    signals = convert_to_signal(values=X, positions=ptime, window=conf_gauss_window)\n",
    "    signals = signals.T  # assumption made downstream\n",
    "    # 3) Detrend + Wavelet + TES\n",
    "    print(\"[5/8] Computing TES (per gene)...\")\n",
    "    n_genes = signals.shape[1]\n",
    "    tes = np.zeros(n_genes, dtype=float)\n",
    "    peak_scale = np.zeros(n_genes, dtype=float)\n",
    "    peak_t = np.zeros(n_genes, dtype=float)\n",
    "    peak_sign = np.zeros(n_genes, dtype=float)\n",
    "    centers = conf_gauss_window.window_centers\n",
    "    t_feat = centers.reshape(-1, 1)\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    step = max(1, n_genes // 20)\n",
    "    for j in range(n_genes):\n",
    "        if j % step == 0:\n",
    "            print(f\"       wavelets: {j:,}/{n_genes:,}\")\n",
    "\n",
    "        sig = signals[:, j]\n",
    "        if detrend_monotonic:  # shouldn't matter for wavelets\n",
    "            lr.fit(t_feat, sig)\n",
    "            sig = sig - lr.predict(t_feat)\n",
    "\n",
    "        coefs, _ = pywt.cwt(sig, scales=scales, wavelet=wavelet)\n",
    "        tes[j] = transient_event_score(coefs)\n",
    "\n",
    "        s_idx, t_idx = np.unravel_index(np.argmax(np.abs(coefs)), coefs.shape)\n",
    "        pt = float(t_idx / (n_windows - 1))\n",
    "        peak_t[j] = pt\n",
    "        peak_scale[j] = float(scales[s_idx])\n",
    "        peak_sign[j] = float(np.sign(coefs[s_idx, t_idx]))\n",
    "\n",
    "        if pt < edge_frac or pt > (1.0 - edge_frac):\n",
    "            tes[j] = np.nan\n",
    "\n",
    "    res = pd.DataFrame({\n",
    "        \"gene\": var_names_arr,\n",
    "        \"TES\": tes,\n",
    "        \"peak_pseudotime\": peak_t,\n",
    "        \"peak_scale\": peak_scale,\n",
    "        \"peak_sign\": peak_sign,\n",
    "    }).dropna(subset=[\"TES\"]).sort_values(\"TES\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # 4) Two-stage permutation p-values (topK only)\n",
    "    if do_perms:\n",
    "        print(\"[6/8] Two-stage permutations (topK only)...\")\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        topK = min(topK_for_perms, len(res))\n",
    "        genes_test = res.loc[:topK-1, \"gene\"].astype(str).to_numpy()\n",
    "\n",
    "        idx_test = np.array([gene_to_idx[g] for g in genes_test], dtype=int)\n",
    "\n",
    "        tes_obs = tes[idx_test].copy()\n",
    "        gt = np.zeros_like(tes_obs, dtype=float)\n",
    "\n",
    "        X_test = X[:, idx_test]  # (cells, topK)\n",
    "        wt = WaveletTransform(wavelet=params[\"wavelet\"],\n",
    "                              scales=params[\"scales\"])\n",
    "        tes, pvals, _ = permutation_dist(values=X_test,\n",
    "                                         positions=ptime,\n",
    "                                         n_permutations=n_perms,\n",
    "                                         wavelet_transform=wt)\n",
    "        \n",
    "        pmap = dict(zip(genes_test, pvals))\n",
    "        res[\"p_perm\"] = res[\"gene\"].astype(str).map(pmap)\n",
    "\n",
    "        tested_mask = res[\"p_perm\"].notna()\n",
    "        res.loc[tested_mask, \"q_perm_bh\"] = false_discovery_control(res.loc[tested_mask, \"p_perm\"].to_numpy(), method=\"bh\")\n",
    "        res.loc[tested_mask, \"q_perm_bh\"] = false_discovery_control(res.loc[tested_mask, \"p_perm\"].to_numpy(), method=\"bh\")\n",
    "    else:\n",
    "        print(\"[6/8] Skipping permutations (do_perms=False)\")\n",
    "\n",
    "    # 5) Cluster trajectories by shape\n",
    "    cluster_info = None\n",
    "    if do_cluster:\n",
    "        print(\"[7/8] Clustering trajectories (k-means)...\")\n",
    "        if cluster_topN is None:\n",
    "            use_genes = res[\"gene\"].astype(str).to_numpy()\n",
    "        else:\n",
    "            use_genes = res.head(min(cluster_topN, len(res)))[\"gene\"].astype(str).to_numpy()\n",
    "\n",
    "        use_idx = np.array([gene_to_idx[g] for g in use_genes], dtype=int)\n",
    "\n",
    "        S = signals[:, use_idx].T  # (n_use_genes, n_windows)\n",
    "\n",
    "        if detrend_monotonic:\n",
    "            Sd = np.zeros_like(S)\n",
    "            for i in range(S.shape[0]):\n",
    "                lr.fit(t_feat, S[i])\n",
    "                Sd[i] = S[i] - lr.predict(t_feat)\n",
    "            S = Sd\n",
    "\n",
    "        S = StandardScaler(with_mean=True, with_std=True).fit_transform(S)\n",
    "        labels = KMeans(n_clusters=n_clusters, random_state=0, n_init=20).fit_predict(S)\n",
    "\n",
    "        cl_map = dict(zip(use_genes, labels))\n",
    "        res[\"cluster\"] = res[\"gene\"].astype(str).map(cl_map)\n",
    "\n",
    "        cluster_info = {\n",
    "            \"use_genes\": use_genes,\n",
    "            \"labels\": labels,\n",
    "            \"n_clusters\": n_clusters,\n",
    "        }\n",
    "    else:\n",
    "        print(\"[7/8] Skipping clustering (do_cluster=False)\")\n",
    "\n",
    "    # Save cache\n",
    "    out = {\n",
    "        \"res\": res,\n",
    "        \"signals\": signals,\n",
    "        \"centers\": centers,\n",
    "        \"ptime\": ptime,\n",
    "        \"var_names_arr\": var_names_arr,\n",
    "        \"gene_to_idx\": gene_to_idx,\n",
    "        \"cluster_info\": cluster_info,\n",
    "        \"params\": params,\n",
    "    }\n",
    "    if cache_path is not None:\n",
    "        print(f\"[8/8] Saving cache to: {cache_path}\")\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump(out, f)\n",
    "\n",
    "    print(f\"[done] total time: {(time.time() - t0):.1f} sec\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e31835-c09a-4fd0-a2b0-03d1561552bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = run_or_load(cache_path)\n",
    "out = run_or_load(None)\n",
    "\n",
    "res = out[\"res\"]\n",
    "signals = out[\"signals\"]\n",
    "centers = out[\"centers\"]\n",
    "gene_to_idx = out[\"gene_to_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3da60f-2898-4ef4-a25c-81ca5b8cc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2)\n",
    "adata_out.obs[\"Week\"] = adata_out.obs[\"time\"]\n",
    "_ = p.plot_identified_gene_coefficients(adata_out, n_top=6, ax=ax[0,1])\n",
    "_ = p.plot_labels_over_psupertime(adata_out, \"Week\", ax=ax[0,0])\n",
    "ax[0,1].set_ylabel(\"Gene\")\n",
    "\n",
    "# PLOT cluster-average trajectories (if cluster exists)\n",
    "cluster_ax = ax[1,0]\n",
    "if \"cluster\" in res.columns and res[\"cluster\"].notna().any():\n",
    "    print(\"[plot] Cluster-average trajectories...\")\n",
    "    # plt.figure(figsize=(7, 4))\n",
    "    for c in sorted(res[\"cluster\"].dropna().unique()):\n",
    "        genes_c = res.loc[res[\"cluster\"] == c, \"gene\"].astype(str).to_list()\n",
    "        idx_c = np.array([gene_to_idx[g] for g in genes_c], dtype=int)\n",
    "        traj = signals[:, idx_c].mean(axis=1)\n",
    "\n",
    "        if detrend_monotonic:\n",
    "            lr = LinearRegression()\n",
    "            t_feat = centers.reshape(-1, 1)\n",
    "            lr.fit(t_feat, traj)\n",
    "            traj = traj - lr.predict(t_feat)\n",
    "\n",
    "        cluster_ax.plot(centers, traj, label=f\"{int(c)} (n={len(idx_c)})\", linewidth=2.5)\n",
    "\n",
    "    cluster_ax.set_xlabel(\"psupertime (window centers)\")\n",
    "    cluster_ax.set_ylabel(\"Mean windowed trajectory\")\n",
    "    cluster_ax.set_title(\"Cluster-average trajectories\")\n",
    "    cluster_ax.legend(title=\"Cluster\", loc=\"lower right\")\n",
    "    # cluster_ax.tight_layout()\n",
    "    # cluster_ax.show()\n",
    "\n",
    "# PLOT top spike-like genes\n",
    "print(\"[plot] Top spike-like genes...\")\n",
    "# res.head(top_plot_n)[\"Gene\"] = res.head(top_plot_n)[\"gene\"]\n",
    "top_genes = res.head(top_plot_n)[\"gene\"].astype(str).tolist()\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "spike_gene_ax = ax[1,1]\n",
    "for g in top_genes:\n",
    "    j = gene_to_idx.get(g, None)\n",
    "    if j is None:\n",
    "        print(\"[plot] missing gene:\", repr(g))\n",
    "        continue\n",
    "\n",
    "    sig = signals[:, j].copy()\n",
    "    if detrend_monotonic:\n",
    "        lr = LinearRegression()\n",
    "        t_feat = centers.reshape(-1, 1)\n",
    "        lr.fit(t_feat, sig)\n",
    "        sig = sig - lr.predict(t_feat)\n",
    "\n",
    "    spike_gene_ax.plot(centers, sig, label=g, alpha=0.95, linewidth=2.5, marker=\".\")\n",
    "\n",
    "spike_gene_ax.set_xlabel(\"Psupertime (window centers)\")\n",
    "spike_gene_ax.set_ylabel(\"Windowed abundance (detrended)\" if detrend_monotonic else \"windowed abundance\")\n",
    "spike_gene_ax.set_title(\"Top spike-like genes\")\n",
    "spike_gene_ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "fig.set_size_inches(10,8)\n",
    "fig.tight_layout()\n",
    "print(res.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd3309-23c8-4453-b4ab-c73a8bd0f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d26f8-87a5-429a-97e4-b16eb2736556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster-average trajectories (show n, use median to be robust)\n",
    "labels = out[\"cluster_info\"][\"labels\"]\n",
    "use_genes = out[\"cluster_info\"][\"use_genes\"]\n",
    "use_idx_map = out[\"gene_to_idx\"]\n",
    "signals = out[\"signals\"]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "for c in sorted(np.unique(labels)):\n",
    "    g_c = use_genes[labels == c]\n",
    "    idx_c = np.array([use_idx_map[g] for g in g_c], dtype=int)\n",
    "    M = signals[:, idx_c]  # (n_windows, n_genes_in_cluster)\n",
    "\n",
    "    if detrend_monotonic:\n",
    "        # detrend each gene quickly\n",
    "        Md = np.zeros_like(M)\n",
    "        for k in range(M.shape[1]):\n",
    "            lr.fit(t_feat, M[:, k])\n",
    "            Md[:, k] = M[:, k] - lr.predict(t_feat)\n",
    "        M = Md\n",
    "\n",
    "    med = np.median(M, axis=1)\n",
    "    plt.plot(centers, med, label=f\"cluster {c} (n={len(g_c)})\", linewidth=3)\n",
    "\n",
    "plt.xlabel(\"psupertime (window centers)\")\n",
    "plt.ylabel(\"median windowed trajectory\")\n",
    "plt.title(\"Cluster-average trajectories (median)\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('total clusters.svg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eede63b-4dd0-43ec-8f62-01e274951186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4986db-3a8d-435f-9e7e-978f5692e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaada1-bd11-40e5-b0dd-1000bed33aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# genes you want to plot\n",
    "genes_to_plot = [\"CALB1\", \"NEFH\", \"GPRIN3\", \"GRID1\"]\n",
    "\n",
    "# ALWAYS resolve from adata_out, never from a reused variable\n",
    "var_names = np.asarray(adata_out.var_names).astype(str)\n",
    "\n",
    "def find_gene_index(target, var_names):\n",
    "    # 1) exact match\n",
    "    hits = np.where(var_names == target)[0]\n",
    "    if hits.size > 0:\n",
    "        return int(hits[0]), target, \"exact\"\n",
    "\n",
    "    # 2) case-insensitive exact match\n",
    "    hits = np.where(np.char.lower(var_names) == target.lower())[0]\n",
    "    if hits.size > 0:\n",
    "        return int(hits[0]), var_names[hits[0]], \"case-insensitive exact\"\n",
    "\n",
    "    # 3) contains (case-insensitive) fallback\n",
    "    mask = np.char.find(np.char.lower(var_names), target.lower()) >= 0\n",
    "    hits = np.where(mask)[0]\n",
    "    if hits.size > 0:\n",
    "        return int(hits[0]), var_names[hits[0]], f\"contains (picked 1 of {hits.size})\"\n",
    "\n",
    "    return None, None, \"missing\"\n",
    "\n",
    "# Resolve gene indices with logging\n",
    "resolved = []\n",
    "\n",
    "print(\"Resolving genes against adata_out.var_names:\")\n",
    "for g in genes_to_plot:\n",
    "    idx, matched_name, how = find_gene_index(g, var_names)\n",
    "    print(f\"  {g:8s} -> {how}\" + (f\" : {matched_name}\" if matched_name else \"\"))\n",
    "    if idx is not None:\n",
    "        resolved.append((g, idx, matched_name, how))\n",
    "\n",
    "if len(resolved) == 0:\n",
    "    raise ValueError(\n",
    "        \"None of the requested genes were found in adata_out.var_names. \"\n",
    "        \"Check gene naming (symbols vs IDs).\"\n",
    "    )\n",
    "\n",
    "# Plot trajectories\n",
    "# plt.figure(figsize=(5, 4))\n",
    "rep_transient_ax = ax[2,0]\n",
    "for g, j, matched_name, how in resolved:\n",
    "    sig = signals[:, j].copy()\n",
    "\n",
    "    # detrend if used upstream\n",
    "    if detrend_monotonic:\n",
    "        lr.fit(t_feat, sig)\n",
    "        sig = sig - lr.predict(t_feat)\n",
    "\n",
    "    label = matched_name if matched_name is not None else g\n",
    "    rep_transient_ax.plot(\n",
    "        centers,\n",
    "        sig,\n",
    "        linewidth=2.8,\n",
    "        alpha=1.0,\n",
    "        label=label\n",
    "    )\n",
    "\n",
    "rep_transient_ax.set_xlabel(\"psupertime (window centers)\")\n",
    "rep_transient_ax.set_ylabel(\"windowed abundance (detrended)\" if detrend_monotonic else \"windowed abundance\")\n",
    "rep_transient_ax.set_title(\"Representative transient trajectories\")\n",
    "rep_transient_ax.legend(frameon=False, fontsize=8)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cea282-a89d-48d8-a92d-7425cb8d1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = res.loc[res[\"q_perm_bh\"] < 0.02].copy()\n",
    "\n",
    "sig[[\"cluster\", \"gene\"]].to_csv(\n",
    "    \"cluster_gene_lists_qlt0.02.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1c169-b333-472e-8e19-b933e2826cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpm = res[res[\"gene\"].str.contains(\"GPM\", case=False, na=False)]\n",
    "print(res_gpm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b212da6-7600-464f-abc5-c7ff0b35e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"psupertime_scTransient_spikes_tuned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f3913-506f-46c9-b0d6-d8a6ae8b0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gene = \"NEFH\"\n",
    "nefh_raw_ax = ax[2,1]\n",
    "# find gene index\n",
    "if gene not in adata_out.var_names:\n",
    "    raise ValueError(f\"{gene} not found in adata_out.var_names\")\n",
    "\n",
    "g_idx = np.where(adata_out.var_names == gene)[0][0]\n",
    "\n",
    "# extract data\n",
    "ptime = adata_out.obs[\"psupertime\"].to_numpy()\n",
    "expr = adata_out.X[:, g_idx]\n",
    "\n",
    "# handle sparse matrix\n",
    "try:\n",
    "    expr = expr.toarray().ravel()\n",
    "except Exception:\n",
    "    expr = np.asarray(expr).ravel()\n",
    "\n",
    "nefh_raw_ax.scatter(ptime, expr, s=40, alpha=0.7)\n",
    "nefh_raw_ax.set_xlabel(\"psupertime\")\n",
    "nefh_raw_ax.set_ylabel(\"NEFH abundance\")\n",
    "nefh_raw_ax.set_title(\"NEFH raw values over psupertime\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb69c1-20cf-4c7e-af56-186e613a0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[0,0].set_title(\"Distribution of labels across pseudotime\")\n",
    "ax[0,1].set_title(\"Genes predictive of pseudotime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6adf5-f6a4-48d9-ab73-5281a09d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ed8b1-9b90-4cb6-8d38-e99171cc1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"ineuron_results.png\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"ineuron_results.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0cb3f-88be-4450-beaa-89184d1d61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = res[res[\"q_perm_bh\"] < 0.02].copy()\n",
    "\n",
    "hits = hits.sort_values(\n",
    "    [\"TES\", \"peak_scale\"],\n",
    "    ascending=[False, False]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c6310-0cea-4995-8c74-da340ff3332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "\n",
    "ranked = hits[[\"gene\", \"TES\"]].dropna()\n",
    "\n",
    "pre_res = gp.prerank(\n",
    "    rnk=ranked,\n",
    "    gene_sets=\"GO_Biological_Process_2023\",\n",
    "    min_size=10,\n",
    "    max_size=300,\n",
    "    permutation_num=1000,\n",
    "    outdir=None,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "pre_res.res2d.sort_values(\"NES\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801913a2-38e1-4acf-8bc4-1bf95fb7e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_res.res2d.sort_values(\"NES\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4024ec-ad90-4cb4-908d-cb99eae7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_res.res2d.sort_values(\"FDR q-val\", ascending=True).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee731b1b-99c5-4a81-b6f2-e22231a1f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) Grab the GSEA results table\n",
    "gsea_df = pre_res.res2d.copy()\n",
    "\n",
    "# Sanity: make sure expected columns exist\n",
    "required_cols = [\"Term\", \"NES\", \"FDR q-val\", \"Lead_genes\"]\n",
    "missing = [c for c in required_cols if c not in gsea_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns in pre_res.res2d: {missing}. Found: {list(gsea_df.columns)}\")\n",
    "\n",
    "# 1) TES-ranked gene list\n",
    "tes_ranked = res.sort_values(\"TES\", ascending=False)[\"gene\"].astype(str).values\n",
    "tes_rank_index = {g: i for i, g in enumerate(tes_ranked)}\n",
    "N = len(tes_ranked)\n",
    "\n",
    "# 2) Helpers\n",
    "def parse_lead_genes(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "\n",
    "    # gseapy can use \";\", sometimes \",\"\n",
    "    if \";\" in s:\n",
    "        parts = s.split(\";\")\n",
    "    elif \",\" in s:\n",
    "        parts = s.split(\",\")\n",
    "    else:\n",
    "        parts = [s]\n",
    "\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "def cumulative_fraction_curve(genes, rank_index, N):\n",
    "    idx = sorted([rank_index[g] for g in genes if g in rank_index])\n",
    "    if len(idx) == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    x = np.arange(N)\n",
    "    y = np.zeros(N, dtype=float)\n",
    "    for i in idx:\n",
    "        y[i:] += 1.0\n",
    "    y /= len(idx)\n",
    "    return x / (N - 1), y, len(idx)\n",
    "\n",
    "def make_unique_labels(df, base_prefix):\n",
    "    # If terms repeat, make label unique with a counter\n",
    "    counts = {}\n",
    "    labels = []\n",
    "    for term in df[\"Term\"].astype(str).tolist():\n",
    "        key = term\n",
    "        counts[key] = counts.get(key, 0) + 1\n",
    "        suffix = f\" #{counts[key]}\" if counts[key] > 1 else \"\"\n",
    "        labels.append(f\"{base_prefix}: {term}{suffix}\")\n",
    "    return labels\n",
    "\n",
    "# 3) Pick pathways: top 4 by descending NES, and top 4 by ascending FDR q-val\n",
    "#    Then union (dedupe) while keeping a stable order.\n",
    "top_nes = (\n",
    "    gsea_df.dropna(subset=[\"NES\"])\n",
    "    .sort_values(\"NES\", ascending=False)\n",
    "    .head(4)\n",
    "    .copy()\n",
    ")\n",
    "top_nes[\"plot_label\"] = make_unique_labels(top_nes, \"Top NES\")\n",
    "\n",
    "top_fdr = (\n",
    "    gsea_df.dropna(subset=[\"FDR q-val\"])\n",
    "    .sort_values(\"FDR q-val\", ascending=True)\n",
    "    .head(4)\n",
    "    .copy()\n",
    ")\n",
    "top_fdr[\"plot_label\"] = make_unique_labels(top_fdr, \"Top FDR\")\n",
    "\n",
    "# Union and de-dupe by Term, preferring the first occurrence (keeps NES-ranked choices first)\n",
    "to_plot = pd.concat([top_nes, top_fdr], axis=0, ignore_index=True)\n",
    "to_plot = to_plot.drop_duplicates(subset=[\"Term\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(\"Plotting these terms:\")\n",
    "print(to_plot[[\"Term\", \"NES\", \"FDR q-val\"]])\n",
    "\n",
    "# 4) Plot cumulative recovery curves\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "for _, row in to_plot.iterrows():\n",
    "    term = str(row[\"Term\"])\n",
    "    label_prefix = str(row[\"plot_label\"])\n",
    "\n",
    "    lead = parse_lead_genes(row.get(\"Lead_genes\", np.nan))\n",
    "    x, y, n_hit = cumulative_fraction_curve(lead, tes_rank_index, N)\n",
    "    if x is None:\n",
    "        print(f\"Skipping '{term}': 0 lead genes found in TES-ranked list\")\n",
    "        continue\n",
    "\n",
    "    nes = row[\"NES\"]\n",
    "    fdr = row[\"FDR q-val\"]\n",
    "    lab = f\"{label_prefix} (n={n_hit}, NES={nes:.2f}, FDR={fdr:.3g})\"\n",
    "\n",
    "    plt.plot(x, y, label=lab, linewidth=2)\n",
    "\n",
    "# diagonal reference\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Fraction of genes (TES-ranked)\")\n",
    "plt.ylabel(\"Fraction of pathway lead genes recovered\")\n",
    "plt.title(\"Cumulative recovery of GSEA lead genes across TES ranking\")\n",
    "plt.legend(fontsize=7, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.savefig('gsea-ranked.svg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f09c0c-f06b-4eae-ab96-e34a10123caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------- settings --------\n",
    "K_PATHS = 25                 # export this many positive-NES pathways\n",
    "MIN_NES = 0                  # only positive NES\n",
    "USE_Q_FILTER = True          # restrict genes to res[q_perm_bh < 0.02]\n",
    "Q_THRESH = 0.02\n",
    "TOPN_GENES_PER_PATH = 50     # keep only top N TES genes per pathway (after intersection)\n",
    "OUTFILE = \"top_positiveNES_pathways_byTES_leadgenes.tsv\"\n",
    "\n",
    "# -------- inputs --------\n",
    "gsea_df = pre_res.res2d.copy()\n",
    "res_df = res.copy()\n",
    "\n",
    "# sanity checks\n",
    "need_gsea = [\"Term\", \"NES\", \"FDR q-val\", \"Lead_genes\"]\n",
    "missing = [c for c in need_gsea if c not in gsea_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns in pre_res.res2d: {missing}\")\n",
    "\n",
    "if \"gene\" not in res_df.columns or \"TES\" not in res_df.columns:\n",
    "    raise KeyError(\"`res` must have columns: gene, TES\")\n",
    "\n",
    "# optional q filter\n",
    "if USE_Q_FILTER:\n",
    "    if \"q_perm_bh\" not in res_df.columns:\n",
    "        raise KeyError(\"USE_Q_FILTER=True but res has no column 'q_perm_bh'\")\n",
    "    res_df = res_df[res_df[\"q_perm_bh\"].notna() & (res_df[\"q_perm_bh\"] < Q_THRESH)].copy()\n",
    "\n",
    "# make lookup: gene -> TES, q\n",
    "res_df[\"gene\"] = res_df[\"gene\"].astype(str)\n",
    "tes_map = dict(zip(res_df[\"gene\"], res_df[\"TES\"]))\n",
    "q_map = dict(zip(res_df[\"gene\"], res_df[\"q_perm_bh\"])) if \"q_perm_bh\" in res_df.columns else {}\n",
    "\n",
    "# helpers\n",
    "def parse_lead_genes(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    if \";\" in s:\n",
    "        parts = s.split(\";\")\n",
    "    elif \",\" in s:\n",
    "        parts = s.split(\",\")\n",
    "    else:\n",
    "        parts = [s]\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "def summarize_genes(glist):\n",
    "    return \";\".join(glist)\n",
    "\n",
    "# pick top K positive NES pathways\n",
    "paths = (\n",
    "    gsea_df.dropna(subset=[\"NES\"])\n",
    "    .loc[gsea_df[\"NES\"] > MIN_NES]\n",
    "    .sort_values(\"NES\", ascending=False)  # if you meant \"top by NES\"\n",
    "    .head(K_PATHS)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for _, r in paths.iterrows():\n",
    "    term = str(r[\"Term\"])\n",
    "    nes = float(r[\"NES\"])\n",
    "    fdr = float(r[\"FDR q-val\"]) if pd.notna(r[\"FDR q-val\"]) else np.nan\n",
    "\n",
    "    lead = parse_lead_genes(r.get(\"Lead_genes\", np.nan))\n",
    "    lead_set = [g for g in lead if g in tes_map]  # present in TES (and pass q filter if enabled)\n",
    "\n",
    "    # rank lead genes by TES\n",
    "    lead_ranked = sorted(lead_set, key=lambda g: tes_map.get(g, -np.inf), reverse=True)\n",
    "    lead_ranked = lead_ranked[:TOPN_GENES_PER_PATH]\n",
    "\n",
    "    # assemble per-gene strings like GENE(TES=...,q=...)\n",
    "    gene_summ = []\n",
    "    for g in lead_ranked:\n",
    "        tesv = tes_map.get(g, np.nan)\n",
    "        qv = q_map.get(g, np.nan) if q_map else np.nan\n",
    "        if np.isfinite(qv):\n",
    "            gene_summ.append(f\"{g}(TES={tesv:.3f},q={qv:.3g})\")\n",
    "        else:\n",
    "            gene_summ.append(f\"{g}(TES={tesv:.3f})\")\n",
    "\n",
    "    rows.append({\n",
    "        \"Term\": term,\n",
    "        \"NES\": nes,\n",
    "        \"FDR_qval\": fdr,\n",
    "        \"n_lead_genes_total\": len(lead),\n",
    "        \"n_lead_genes_in_TES_list\": len(lead_set),\n",
    "        \"top_lead_genes_by_TES\": summarize_genes(lead_ranked),\n",
    "        \"top_lead_genes_by_TES_with_scores\": summarize_genes(gene_summ),\n",
    "        \"all_lead_genes_raw\": summarize_genes(lead),\n",
    "    })\n",
    "\n",
    "export_df = pd.DataFrame(rows).sort_values([\"NES\", \"FDR_qval\"], ascending=[False, True])\n",
    "export_df.to_csv(OUTFILE, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Wrote: {OUTFILE}\")\n",
    "print(export_df.head(10)[[\"Term\",\"NES\",\"FDR_qval\",\"n_lead_genes_in_TES_list\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91799e-f052-4e80-83cf-ca0c9976863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_plot = {\n",
    "    \"Stem cell maintenance\": \"HMGA2\",\n",
    "    \"Positive stem cell maintenance\": \"SMARCA4\",\n",
    "    \"Negative regulation of development\": \"THY1\",\n",
    "    \"DSB repair regulation\": \"KDM1A\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc07b9-f608-4db0-bd71-018ba503d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def rescale_to(sig, target):\n",
    "    sig = np.asarray(sig, float)\n",
    "    target = np.asarray(target, float)\n",
    "    sig = (sig - sig.mean()) / (sig.std() + 1e-12)\n",
    "    return sig * target.std() + target.mean()\n",
    "\n",
    "def nearest_center_index(pt01, centers):\n",
    "    # pt01 is 0..1; centers is array of window centers in 0..1\n",
    "    return int(np.argmin(np.abs(centers - float(pt01))))\n",
    "\n",
    "def get_gene_index_map(adata):\n",
    "    v = np.asarray(adata.var_names).astype(str)\n",
    "    return v, {g: i for i, g in enumerate(v)}\n",
    "\n",
    "# ---------- choose genes to plot ----------\n",
    "genes_to_plot = [\"HMGA2\", \"SMARCA4\"]  # edit\n",
    "\n",
    "var_names, gene_to_idx = get_gene_index_map(adata_out)\n",
    "\n",
    "missing = [g for g in genes_to_plot if g not in gene_to_idx]\n",
    "if missing:\n",
    "    raise ValueError(f\"Not found in adata_out.var_names: {missing[:20]}{'...' if len(missing)>20 else ''}\")\n",
    "\n",
    "# ---------- raw data ordered by psupertime ----------\n",
    "X_raw = adata_out.X\n",
    "try:\n",
    "    import scipy.sparse as sp\n",
    "    if sp.issparse(X_raw):\n",
    "        X_raw = X_raw.toarray()\n",
    "except Exception:\n",
    "    X_raw = np.asarray(X_raw)\n",
    "\n",
    "ptime_raw = adata_out.obs[ptime_col].to_numpy().astype(float)\n",
    "order = np.argsort(ptime_raw)\n",
    "\n",
    "ptime_sorted = ptime_raw[order]\n",
    "ptime_scaled = (ptime_sorted - ptime_sorted.min()) / (ptime_sorted.max() - ptime_sorted.min() + 1e-12)\n",
    "\n",
    "X_sorted = np.asarray(X_raw, float)[order, :]\n",
    "\n",
    "# match upstream z-scoring choice\n",
    "if zscore_genes:\n",
    "    X_sorted = (X_sorted - X_sorted.mean(axis=0, keepdims=True)) / (X_sorted.std(axis=0, keepdims=True) + 1e-12)\n",
    "\n",
    "lr = LinearRegression()\n",
    "t_feat = centers.reshape(-1, 1)\n",
    "\n",
    "# ---------- plotting ----------\n",
    "for g in genes_to_plot:\n",
    "    j = gene_to_idx[g]\n",
    "\n",
    "    # pull stored peak info from res\n",
    "    row = res.loc[res[\"gene\"].astype(str) == g]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"{g} not found in res['gene']. Are you plotting genes not in the TES results?\")\n",
    "    row = row.iloc[0]\n",
    "\n",
    "    peak_pt01 = float(row[\"peak_pseudotime\"])\n",
    "    peak_scale_val = float(row[\"peak_scale\"])\n",
    "    peak_sign = float(row.get(\"peak_sign\", np.nan))\n",
    "\n",
    "    # map peak pseudotime to a window index\n",
    "    t_idx_from_res = nearest_center_index(peak_pt01, centers)\n",
    "\n",
    "    # windowed trajectory (from precomputed signals)\n",
    "    y_win = signals[:, j].copy()\n",
    "    if detrend_monotonic:\n",
    "        lr.fit(t_feat, y_win)\n",
    "        y_win = y_win - lr.predict(t_feat)\n",
    "\n",
    "    # wavelet coefficients on the same signal used for TES\n",
    "    coefs, _ = pywt.cwt(y_win, scales=scales, wavelet=wavelet)\n",
    "\n",
    "    # find nearest scale index to stored peak_scale\n",
    "    s_idx_from_res = int(np.argmin(np.abs(scales - peak_scale_val)))\n",
    "\n",
    "    # coefficient time series at that scale\n",
    "    wave_line = coefs[s_idx_from_res, :]\n",
    "    # wave_line = np.abs(wave_line) * (1.0 if np.isnan(peak_sign) else np.sign(peak_sign))\n",
    "\n",
    "    wave_overlay = rescale_to(wave_line, y_win)\n",
    "\n",
    "    # sanity check: does recomputed global max agree with stored peak?\n",
    "    s_idx_max, t_idx_max = np.unravel_index(np.argmax(np.abs(coefs)), coefs.shape)\n",
    "    pt_max = t_idx_max / (len(centers) - 1)\n",
    "    sc_max = float(scales[s_idx_max])\n",
    "\n",
    "    print(\n",
    "        f\"{g}: stored peak_pt={peak_pt01:.3f} (t_idx={t_idx_from_res}), stored scale={peak_scale_val:.1f} \"\n",
    "        f\"| recomputed max_pt={pt_max:.3f} (t_idx={t_idx_max}), max scale={sc_max:.1f}\"\n",
    "    )\n",
    "\n",
    "    # raw points\n",
    "    y_raw = X_sorted[:, j]\n",
    "\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    plt.scatter(ptime_scaled, y_raw, s=12, alpha=0.25, label=\"raw (z-scored)\")\n",
    "\n",
    "    plt.plot(centers, y_win, linewidth=2.8, label=\"windowed trajectory (detrended)\" if detrend_monotonic else \"windowed trajectory\")\n",
    "\n",
    "    plt.plot(centers, wave_overlay, linewidth=2.2, linestyle=\"--\",\n",
    "             label=f\"wavelet coef @ scale={scales[s_idx_from_res]} (from res)\")\n",
    "\n",
    "    # vertical line at stored peak\n",
    "    plt.axvline(centers[t_idx_from_res], linestyle=\":\", alpha=0.7,\n",
    "                label=f\"stored peak (pt={centers[t_idx_from_res]:.2f})\")\n",
    "\n",
    "    plt.xlabel(\"psupertime\")\n",
    "    plt.ylabel(\"abundance\")\n",
    "    plt.title(f\"{g} (TES={row['TES']:.3f}, q={row.get('q_perm_bh', np.nan):.3g})\")\n",
    "    plt.legend(frameon=False, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b5f8e-bbc1-4123-9cf9-d477094cb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Load the pathway data and get top 4 by NES\n",
    "df_pathways = pd.read_csv('top_positiveNES_pathways_byTES_leadgenes.tsv', sep='\\t')\n",
    "top_4_pathways = df_pathways.sort_values(by='NES', ascending=False).head(4)\n",
    "\n",
    "# 2. Setup indices from your adata object (assumes adata_out exists in your env)\n",
    "var_names = np.asarray(adata_out.var_names).astype(str)\n",
    "gene_to_idx = {g: i for i, g in enumerate(var_names)}\n",
    "\n",
    "# Detrending model setup (as per your template)\n",
    "lr = LinearRegression()\n",
    "t_feat = centers.reshape(-1, 1)\n",
    "\n",
    "# 3. Generate one plot per pathway\n",
    "for idx, row in top_4_pathways.iterrows():\n",
    "    pathway_name = row['Term']\n",
    "    # Split the raw lead genes string into a list\n",
    "    genes_in_pathway = row['all_lead_genes_raw'].split(';')\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    genes_plotted_count = 0\n",
    "    for gene in genes_in_pathway:\n",
    "        if gene in gene_to_idx:\n",
    "            j = gene_to_idx[gene]\n",
    "            \n",
    "            # Extract windowed signal (assumes 'signals' and 'centers' exist)\n",
    "            y_win = signals[:, j].copy()\n",
    "            \n",
    "            # Apply detrending if your pipeline uses it\n",
    "            if detrend_monotonic:\n",
    "                lr.fit(t_feat, y_win)\n",
    "                y_win = y_win - lr.predict(t_feat)\n",
    "            \n",
    "            # Plot the smoothed trajectory for this gene\n",
    "            plt.plot(\n",
    "                centers, \n",
    "                y_win, \n",
    "                linewidth=2, \n",
    "                alpha=0.7, \n",
    "                label=gene\n",
    "            )\n",
    "            genes_plotted_count += 1\n",
    "            \n",
    "    # Formatting the plot\n",
    "    plt.title(f\"Top Lead Genes: {pathway_name}\\n(NES: {row['NES']:.2f})\", fontsize=12)\n",
    "    plt.xlabel(\"psupertime\", fontsize=10)\n",
    "    plt.ylabel(\"z-scored abundance (windowed)\", fontsize=10)\n",
    "    \n",
    "    # Place legend outside if there are many genes\n",
    "    if genes_plotted_count > 0:\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False, fontsize=8)\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python311 (sctransient notebook)",
   "language": "python",
   "name": "sctransient_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
